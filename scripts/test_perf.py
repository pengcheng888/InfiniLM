import asyncio
import time
from openai import AsyncOpenAI
import argparse
import random


PROMPTS = [
    "å¦‚æœçŒ«èƒ½å†™è¯—ï¼Œå®ƒä»¬ä¼šå†™äº›ä»€ä¹ˆï¼Ÿ",
    # "æè¿°ä¸€ä¸ªæ²¡æœ‰é‡åŠ›çš„ä¸–ç•Œã€‚",
    # "å¦‚æœåœ°çƒåœæ­¢è‡ªè½¬ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ",
    # "å‡è®¾ä½ æ˜¯ä¸€åªä¼šé£çš„é²¸é±¼ï¼Œæè¿°ä½ çš„æ—¥å¸¸ç”Ÿæ´»ã€‚",
    # "å¦‚æœäººç±»å¯ä»¥ä¸æ¤ç‰©æ²Ÿé€šï¼Œä¸–ç•Œä¼šå˜æˆä»€ä¹ˆæ ·ï¼Ÿ",
    # "æè¿°ä¸€ä¸ªç”±ç³–æœæ„æˆçš„åŸå¸‚ã€‚",
    # "å¦‚æœæ—¶é—´æ—…è¡Œæˆä¸ºå¯èƒ½ï¼Œä½ æœ€æƒ³å»å“ªä¸ªæ—¶ä»£ï¼Ÿ",
    # "æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœåœ°çƒä¸Šåªæœ‰è“è‰²ï¼Œå…¶ä»–é¢œè‰²éƒ½æ¶ˆå¤±äº†ã€‚",
    # "å¦‚æœåŠ¨ç‰©èƒ½ä¸Šç½‘ï¼Œå®ƒä»¬ä¼šæµè§ˆä»€ä¹ˆç½‘ç«™ï¼Ÿ",
    # "æè¿°ä¸€ä¸ªæ²¡æœ‰å£°éŸ³çš„ä¸–ç•Œã€‚",
    # "å¦‚æœäººç±»å¯ä»¥åœ¨æ°´ä¸‹å‘¼å¸ï¼ŒåŸå¸‚ä¼šå¦‚ä½•å˜åŒ–ï¼Ÿ",
    # "æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœå¤©ç©ºæ˜¯ç»¿è‰²çš„ï¼Œäº‘æ˜¯ç´«è‰²çš„ã€‚",
    # "å¦‚æœä½ èƒ½ä¸ä»»ä½•å†å²äººç‰©å…±è¿›æ™šé¤ï¼Œä½ ä¼šé€‰æ‹©è°ï¼Ÿ",
    # "æè¿°ä¸€ä¸ªæ²¡æœ‰å¤œæ™šçš„æ˜Ÿçƒã€‚",
    # "å¦‚æœåœ°çƒä¸Šåªæœ‰ä¸€ç§è¯­è¨€ï¼Œä¸–ç•Œä¼šå¦‚ä½•è¿ä½œï¼Ÿ",
    # "æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœæ‰€æœ‰çš„ä¹¦éƒ½å˜æˆäº†éŸ³ä¹ã€‚",
    # "å¦‚æœä½ å¯ä»¥å˜æˆä»»ä½•ä¸€ç§åŠ¨ç‰©ï¼Œä½ ä¼šé€‰æ‹©ä»€ä¹ˆï¼Ÿ",
    # "æè¿°ä¸€ä¸ªç”±æœºå™¨äººç»Ÿæ²»çš„æœªæ¥ä¸–ç•Œã€‚",
    # "å¦‚æœä½ èƒ½ä¸ä»»ä½•è™šæ„è§’è‰²æˆä¸ºæœ‹å‹ï¼Œä½ ä¼šé€‰æ‹©è°ï¼Ÿ",
    # "æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœæ¯ä¸ªäººéƒ½èƒ½è¯»æ‡‚ä»–äººçš„æ€æƒ³ã€‚"
]
# åˆ›å»ºä¸€ä¸ªå¹¶å‘æµ‹è¯•ç¯å¢ƒï¼Œæ¨¡æ‹Ÿ CONCURRENCY ä¸ªç”¨æˆ·åŒæ—¶å‘é€ NUM_REQUESTS ä¸ªè¯·æ±‚ã€‚
NUM_REQUESTS = 1
CONCURRENCY = 1
API_URL = "http://127.0.0.1:8000"
MODEL = "FM9G-7B"


# -------------------------------------------------------------------- #
#             æ¨¡æ‹Ÿä¸€ä¸ªå¹¶å‘ç”¨æˆ·æ‰§è¡ŒAPIè¯·æ±‚æµ‹è¯•ï¼Œæ”¶é›†è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡æ•°æ®ã€‚
# ---------------------------------------------------------------------#
async def benchmark_user(
    client,  # OpenAIå®¢æˆ·ç«¯
    semaphore,  # å¹¶å‘æ§åˆ¶
    queue,  # ä»»åŠ¡é˜Ÿåˆ—
    results,  # æ”¶é›†æµ‹è¯•ç»“æœ
    user_id,  # ç”¨æˆ·æ ‡è¯†
    verbose,  # æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
):
    # -------------------------------------------------------------------- #
    #             æŒç»­ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼Œç›´åˆ°é‡åˆ° None ç»“æŸä¿¡å·
    #             ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘ï¼Œé˜²æ­¢è¿‡å¤šè¯·æ±‚åŒæ—¶å‘é€
    # ---------------------------------------------------------------------#
    while True:
        async with semaphore:  # è·å–å¹¶å‘è®¸å¯
            task_id = await queue.get()  #  ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
            if task_id is None:  # é‡åˆ°ç»“æŸä¿¡å·
                queue.task_done()
                break

            question = random.choice(PROMPTS)  #  éšæœºé€‰æ‹©æç¤ºè¯
            try:
                print(f"ğŸš€ User#{user_id} Sending request #{task_id}")

                # -------------------------------------------------------------------- #
                #             å‘é€è¯·æ±‚å¹¶è®¡æ—¶
                # ---------------------------------------------------------------------#
                start_time = time.time()
                print("test_perf------------->  111111")
                stream = await client.chat.completions.create(
                    model=MODEL,
                    messages=[{"role": "user", "content": question}],
                    stream=True,
                )
                print("test_perf------------->  2222222222222222")
                first_token_time = None  # é¦–ä¸ªtokenåˆ°è¾¾æ—¶é—´
                total_tokens = 0  # æ€»tokenè®¡æ•°
                answer_chunks = []  # å›ç­”å†…å®¹æ”¶é›†

                print("test_perf------------->  33333333333333333")
                async for chunk in stream:
                    if first_token_time is None:  # è®°å½•é¦–ä¸ªtokenæ—¶é—´
                        first_token_time = time.time()

                    delta = chunk.choices[0].delta.content
                    if delta:
                        answer_chunks.append(delta)
                        total_tokens += 1  # ç»Ÿè®¡tokenæ•°é‡

                    if chunk.choices[0].finish_reason is not None:  # æµç»“æŸ
                        break

                end_time = time.time()

                # -------------------------------------------------------------------- #
                #             æ€§èƒ½æŒ‡æ ‡è®¡ç®—
                # ---------------------------------------------------------------------#
                ttft = first_token_time - start_time if first_token_time else None
                elapsed_time = end_time - start_time if start_time else None
                ms_per_token = (
                    (elapsed_time / total_tokens * 1000)
                    if total_tokens > 0 and elapsed_time
                    else None
                )
                tokens_per_second = (
                    total_tokens / elapsed_time if elapsed_time > 0 else 0
                )

                # -------------------------------------------------------------------- #
                #              ç»“æœæ”¶é›†
                # ---------------------------------------------------------------------#
                answer = "".join(answer_chunks)  # æ‹¼æ¥å®Œæ•´å›ç­”

                results.append(
                    (total_tokens, elapsed_time, tokens_per_second, ttft, ms_per_token)
                )

                if verbose:
                    print(f"\nğŸ“ Request #{task_id} (User #{user_id})")
                    print(f"  â± é¦–å­—å»¶è¿Ÿ TTFT: {ttft:.3f}s")
                    print(f"  â± æ€»è€—æ—¶: {elapsed_time:.3f}s")
                    print(f"  ğŸ”¤ è§£ç  token æ€»æ•°: {total_tokens}")
                    print(f"  ğŸ“ å¹³å‡ token è§£ç æ—¶é—´: {ms_per_token:.2f} ms/token")
                    print(f"  â“ æé—®: {question}")
                    print(f"  ğŸ’¬ å›ç­”: {answer}\n")

                queue.task_done()  # æ ‡è®°ä»»åŠ¡å®Œæˆ
            except Exception as e:
                if verbose:
                    print(f"\nâš ï¸ Request #{task_id} (User #{user_id}) FAILED:")
                    print(f"  âŒ Error: {e}\n")


async def run_benchmark(verbose=False):
    client = AsyncOpenAI(base_url=API_URL, api_key="default")
    # -------------------------------------------------------------------- #
    #                   åˆ›å»ºå¹¶å‘æ§åˆ¶
    # ---------------------------------------------------------------------#
    # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶æœ€å¤§å¹¶å‘æ•°ï¼Œé˜²æ­¢è¿‡å¤šå¹¶å‘è¯·æ±‚å‹å®æœåŠ¡å™¨ã€‚
    semaphore = asyncio.Semaphore(CONCURRENCY)
    print("-------> async def run_benchmark(verbose=False):      11111 ")
    queue = asyncio.Queue()
    results = []

    # -------------------------------------------------------------------- #
    #                  ä»»åŠ¡é˜Ÿåˆ—æœºåˆ¶
    # ---------------------------------------------------------------------#
    # # å¡«å……ä»»åŠ¡é˜Ÿåˆ—
    for i in range(NUM_REQUESTS):
        await queue.put(i)  # é˜Ÿåˆ—ä¸­åŒ…å«æ‰€æœ‰è¦æ‰§è¡Œçš„è¯·æ±‚ç¼–å·ï¼ˆ0åˆ°NUM_REQUESTS-1ï¼‰
    # æ·»åŠ ç»“æŸä¿¡å·
    for _ in range(CONCURRENCY):
        await queue.put(None)  # æ¯ä¸ª None ä½œä¸ºå·¥ä½œçº¿ç¨‹çš„ç»“æŸä¿¡å·

    print("-------> async def run_benchmark(verbose=False):      22222222 ")
    # -------------------------------------------------------------------- #
    #                  åˆ›å»ºå¹¶å‘ç”¨æˆ·ä»»åŠ¡
    # ---------------------------------------------------------------------#
    users = [
        asyncio.create_task(
            benchmark_user(client, semaphore, queue, results, user_id, verbose)
        )
        # åˆ›å»º CONCURRENCY ä¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä»£è¡¨ä¸€ä¸ª"ç”¨æˆ·"
        for user_id in range(CONCURRENCY)
    ]

    start_time = time.time()
    await queue.join()
    await asyncio.gather(*users)
    end_time = time.time()

    total_elapsed_time = end_time - start_time
    tokens_list = [r[0] for r in results if r and r[0] is not None]
    latencies = [r[1] for r in results if r and r[1] is not None]
    tokens_per_second_list = [r[2] for r in results if r and r[2] is not None]
    ttft_list = [r[3] for r in results if r and r[3] is not None]
    ms_per_token_list = [r[4] for r in results if r and r[4] is not None]

    successful_requests = len(results)
    requests_per_second = (
        successful_requests / total_elapsed_time if total_elapsed_time > 0 else 0
    )
    avg_latency = sum(latencies) / len(latencies) if latencies else 0
    avg_tokens_per_second = (
        sum(tokens_per_second_list) / len(tokens_per_second_list)
        if tokens_per_second_list
        else 0
    )
    avg_ttft = sum(ttft_list) / len(ttft_list) if ttft_list else 0
    avg_ms_per_token = (
        sum(ms_per_token_list) / len(ms_per_token_list) if ms_per_token_list else None
    )

    width_label = 24
    sep = "-" * 60

    print(f"\n=== ğŸ“Š æ€§èƒ½æŒ‡æ ‡æ±‡æ€» ({MODEL}) ===")
    print(sep)
    print(f"{'å¹¶å‘æ•°':<{width_label}}: {CONCURRENCY}")
    print(f"{'è¯·æ±‚æ€»æ•°':<{width_label}}: {NUM_REQUESTS}")
    print(f"{'æˆåŠŸè¯·æ±‚æ•°':<{width_label}}: {successful_requests}")
    print(f"{'æ€»è€—æ—¶':<{width_label}}: {total_elapsed_time:.2f} s")
    print(f"{'æ€»è¾“å‡ºtokenæ•°':<{width_label}}: {sum(tokens_list)}")
    print(f"{'è¯·æ±‚é€Ÿç‡ (RPS)':<{width_label}}: {requests_per_second:.2f} requests/s")
    print(sep)
    print(f"{'Average latency':<{width_label}}: {avg_latency:.2f} s")
    print(f"{'Average TTFT':<{width_label}}: {avg_ttft:.2f} s")
    print(f"{'Avg time per token':<{width_label}}: {avg_ms_per_token:.2f} ms/token")
    print(
        f"{'Avg Token generation speed':<{width_label}}: {avg_tokens_per_second:.2f} tokens/s"
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--verbose", action="store_true")
    args = parser.parse_args()

    asyncio.run(run_benchmark(args.verbose))
